{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"\"\"The popularity of social media, online forums, and review websites has significantly contributed to the \n",
    "generation of a vast amount of textual data. Understanding and analyzing this data is crucial for multiple \n",
    "applications such as sentiment analysis, chatbot development, content moderation, and opinion mining. \n",
    "Among various complex tasks associated with text analytics, detecting sarcasm remains an arduous \n",
    "undertaking due to its ironic nature where words portray the opposite intended meaning. One often utilizes \n",
    "sarcasm as a means to express mirth, censure or disdain. A precise detection of sarcastic intent in written \n",
    "communication is pivotal for an accurate interpretation of the conveyed message.\n",
    "Detecting sarcasm in text is a complex endeavor, as it hinges on many contextual factors and subtle \n",
    "linguistic clues that automated programs have difficulty interpreting. Moreover, sarcasm can exhibit marked \n",
    "variations across cultural and linguistic groups, posing additional challenges for modern natural language \n",
    "processing (NLP) tools. As large-scale textual data analysis attains greater prominence across various \n",
    "domains, developing accurate and effective models of sarcasm detection has become an increasingly \n",
    "pressing need\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The popularity of social media, online forums, and review websites has significantly contributed to the \\ngeneration of a vast amount of textual data',\n",
       " ' Understanding and analyzing this data is crucial for multiple \\napplications such as sentiment analysis, chatbot development, content moderation, and opinion mining',\n",
       " ' \\nAmong various complex tasks associated with text analytics, detecting sarcasm remains an arduous \\nundertaking due to its ironic nature where words portray the opposite intended meaning',\n",
       " ' One often utilizes \\nsarcasm as a means to express mirth, censure or disdain',\n",
       " ' A precise detection of sarcastic intent in written \\ncommunication is pivotal for an accurate interpretation of the conveyed message',\n",
       " '\\nDetecting sarcasm in text is a complex endeavor, as it hinges on many contextual factors and subtle \\nlinguistic clues that automated programs have difficulty interpreting',\n",
       " ' Moreover, sarcasm can exhibit marked \\nvariations across cultural and linguistic groups, posing additional challenges for modern natural language \\nprocessing (NLP) tools',\n",
       " ' As large-scale textual data analysis attains greater prominence across various \\ndomains, developing accurate and effective models of sarcasm detection has become an increasingly \\npressing need']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document = doc.split('.')\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-mpnet-base-v2',device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sequence Length: 384\n"
     ]
    }
   ],
   "source": [
    "print(\"Max Sequence Length:\", model.max_seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 768)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.05302034  0.05951107 -0.03653507 ... -0.01434155 -0.03615366\n",
      "  -0.00701014]\n",
      " [ 0.07619365 -0.00084576 -0.04186951 ... -0.00203631 -0.00712318\n",
      "  -0.00228361]\n",
      " [ 0.07875723 -0.00470723 -0.06173111 ...  0.02767393  0.00067155\n",
      "  -0.00589097]\n",
      " ...\n",
      " [ 0.05349918 -0.0090595  -0.05768472 ...  0.03465624  0.00537337\n",
      "  -0.01348786]\n",
      " [ 0.05503198  0.02232661 -0.05980028 ...  0.02945515  0.01413232\n",
      "  -0.04283253]\n",
      " [ 0.07154523  0.0071794  -0.05959034 ...  0.02161732 -0.02539712\n",
      "  -0.01456877]]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "index_name = 'semantic-search-openai'\n",
    "\n",
    "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "pinecone.init(\n",
    "    api_key=\"eeeb80d1-8f75-4ea0-b0ab-b70330f96db3\",\n",
    "    environment=\"us-east1-gcp\"  # find next to api key in console\n",
    ")\n",
    "# check if 'openai' index already exists (only create index if not)\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    pinecone.create_index(index_name, dimension=len(embeddings[0]))\n",
    "# connect to index\n",
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010003805160522461,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690788a531a54e48a8f6c6ce96b18458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "model = SentenceTransformer('all-mpnet-base-v2',device='cuda')\n",
    "\n",
    "count = 0  # we'll use the count to create unique IDs\n",
    "batch_size = 32  # process everything in batches of 32\n",
    "for i in tqdm(range(0, len(document), batch_size)):\n",
    "    # set end position of batch\n",
    "    i_end = min(i+batch_size, len(document))\n",
    "    # get batch of lines and IDs\n",
    "    lines_batch = document[i: i+batch_size]\n",
    "    ids_batch = [str(n) for n in range(i, i_end)]\n",
    "    # create embeddings\n",
    "    embeds =model.encode(lines_batch)\n",
    "    # prep metadata and upsert batch\n",
    "    meta = [{'text': line} for line in lines_batch]\n",
    "    to_upsert = zip(ids_batch, embeds.tolist(), meta)\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=list(to_upsert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"sarcasam detection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': '4',\n",
       "              'metadata': {'text': ' A precise detection of sarcastic intent '\n",
       "                                   'in written \\n'\n",
       "                                   'communication is pivotal for an accurate '\n",
       "                                   'interpretation of the conveyed message'},\n",
       "              'score': 0.18849954,\n",
       "              'values': []},\n",
       "             {'id': '5',\n",
       "              'metadata': {'text': '\\n'\n",
       "                                   'Detecting sarcasm in text is a complex '\n",
       "                                   'endeavor, as it hinges on many contextual '\n",
       "                                   'factors and subtle \\n'\n",
       "                                   'linguistic clues that automated programs '\n",
       "                                   'have difficulty interpreting'},\n",
       "              'score': 0.145075634,\n",
       "              'values': []},\n",
       "             {'id': '2',\n",
       "              'metadata': {'text': ' \\n'\n",
       "                                   'Among various complex tasks associated '\n",
       "                                   'with text analytics, detecting sarcasm '\n",
       "                                   'remains an arduous \\n'\n",
       "                                   'undertaking due to its ironic nature where '\n",
       "                                   'words portray the opposite intended '\n",
       "                                   'meaning'},\n",
       "              'score': 0.127962232,\n",
       "              'values': []},\n",
       "             {'id': '1',\n",
       "              'metadata': {'text': ' Understanding and analyzing this data is '\n",
       "                                   'crucial for multiple \\n'\n",
       "                                   'applications such as sentiment analysis, '\n",
       "                                   'chatbot development, content moderation, '\n",
       "                                   'and opinion mining'},\n",
       "              'score': 0.118142664,\n",
       "              'values': []},\n",
       "             {'id': '7',\n",
       "              'metadata': {'text': ' As large-scale textual data analysis '\n",
       "                                   'attains greater prominence across '\n",
       "                                   'various \\n'\n",
       "                                   'domains, developing accurate and effective '\n",
       "                                   'models of sarcasm detection has become an '\n",
       "                                   'increasingly \\n'\n",
       "                                   'pressing need'},\n",
       "              'score': 0.109556727,\n",
       "              'values': []}],\n",
       " 'namespace': ''}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = model.encode(query)\n",
    "res = index.query([query.tolist()], top_k=5, include_metadata=True)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unsupported file format.\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import PyPDF2\n",
    "from docx import Document\n",
    "\n",
    "def extract_data(file_path):\n",
    "    file_extension = os.path.splitext(file_path)[1]\n",
    "    print(file_extension)\n",
    "\n",
    "    if file_extension == \".txt\":\n",
    "        with open(file_path, \"r\") as file:\n",
    "            content = file.readlines()\n",
    "    elif file_extension == \".pdf\":\n",
    "        pdf_reader = PyPDF2.PdfFileReader(file_path)\n",
    "        content = []\n",
    "        for page_num in range(pdf_reader.numPages):\n",
    "            page = pdf_reader.getPage(page_num)\n",
    "            text = page.extractText()\n",
    "            lines = text.split('\\n')\n",
    "            content.extend(lines)\n",
    "    elif file_extension == \".docx\":\n",
    "        doc = Document(file_path)\n",
    "        content = [paragraph.text for paragraph in doc.paragraphs]\n",
    "    else:\n",
    "        content = []\n",
    "        print(\"Unsupported file format.\")\n",
    "\n",
    "    print(content)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = input(\"Research paper full with lag\")\n",
    "    extract_data(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A precise detection of sarcastic intent in written \n",
      "communication is pivotal for an accurate interpretation of the conveyed message\n",
      "\n",
      "Detecting sarcasm in text is a complex endeavor, as it hinges on many contextual factors and subtle \n",
      "linguistic clues that automated programs have difficulty interpreting\n",
      " \n",
      "Among various complex tasks associated with text analytics, detecting sarcasm remains an arduous \n",
      "undertaking due to its ironic nature where words portray the opposite intended meaning\n",
      " Understanding and analyzing this data is crucial for multiple \n",
      "applications such as sentiment analysis, chatbot development, content moderation, and opinion mining\n",
      " As large-scale textual data analysis attains greater prominence across various \n",
      "domains, developing accurate and effective models of sarcasm detection has become an increasingly \n",
      "pressing need\n"
     ]
    }
   ],
   "source": [
    "for i  in res['matches']:\n",
    "    print(i[\"metadata\"]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
